{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import psycopg2\n",
    "import scraper\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: if no dbname or user are specified, the default is your username.\n",
    "conn = psycopg2.connect(\"dbname=food_db\")\n",
    "cur = conn.cursor()\n",
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page=1\n",
    "urls = scraper.get_urls(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    row = scraper.get_ingredients(url)\n",
    "    query = \"\"\"\n",
    "    INSERT INTO\n",
    "        recipes (post_date, title, foods)\n",
    "        VALUES (%s, %s, %s);\n",
    "    \"\"\"\n",
    "    cur.execute(query, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        SELECT *\n",
    "        FROM recipes\n",
    "        LIMIT 30;\n",
    "        '''\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,\n",
       " datetime.datetime(2018, 2, 9, 0, 0),\n",
       " 'Long Life Noodles with Shrimp and Greens',\n",
       " 'teaspoon sesame oil, for drizzling stalk green onion, finely chopped cups all-purpose flour, plus more for dusting medium carrot, julienned (about 1‚ÅÑ2 cup) stalk green onion, cut into 2-inch segments tablespoon plus 1 teaspoon vegetable oil, divided kosher salt cup water teaspoon minced fresh ginger tablespoon hoisin sauce teaspoon soy sauce teaspoons cornstarch pound raw shrimp, size 16/20, peeled and deveined tablespoons soy sauce cups roughly chopped greens, such as baby bok choy, yu choy, or chinese broccoli cup warm tap water large clove garlic, minced')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM recipes', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df.foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "food_stops = {'pinch', 'serving', 'teaspoon', 'teaspoons', 'tablespoon', 'tablespoons', 'cup', 'cups', \n",
    "              'optional', 'taste', 'oz', 'package', 'see', 'note', 'small', 'medium', 'large', 'cut', \n",
    "              'inch', 'divided', 'pounds', 'pound', 'plus'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sesam',\n",
       " 'oil',\n",
       " 'drizzl',\n",
       " 'stalk',\n",
       " 'green',\n",
       " 'onion',\n",
       " 'fine',\n",
       " 'chop',\n",
       " 'allpurpos',\n",
       " 'flour',\n",
       " 'dust',\n",
       " 'carrot',\n",
       " 'julien',\n",
       " 'stalk',\n",
       " 'green',\n",
       " 'onion',\n",
       " 'segment',\n",
       " 'veget',\n",
       " 'oil',\n",
       " 'kosher',\n",
       " 'salt',\n",
       " 'water',\n",
       " 'minc',\n",
       " 'fresh',\n",
       " 'ginger',\n",
       " 'hoisin',\n",
       " 'sauc',\n",
       " 'soy',\n",
       " 'sauc',\n",
       " 'cornstarch',\n",
       " 'raw',\n",
       " 'shrimp',\n",
       " 'size',\n",
       " 'peel',\n",
       " 'devein',\n",
       " 'soy',\n",
       " 'sauc',\n",
       " 'roughli',\n",
       " 'chop',\n",
       " 'green',\n",
       " 'babi',\n",
       " 'bok',\n",
       " 'choy',\n",
       " 'yu',\n",
       " 'choy',\n",
       " 'chines',\n",
       " 'broccoli',\n",
       " 'warm',\n",
       " 'tap',\n",
       " 'water',\n",
       " 'clove',\n",
       " 'garlic',\n",
       " 'minc']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "doc4 = docs[0]\n",
    "doc4 = ''.join(ch for ch in doc4 if ch in set(string.ascii_lowercase + ' '))\n",
    "doc4 = word_tokenize(doc4)\n",
    "sw = set(stopwords.words('english'))\n",
    "sw.update(food_stops)\n",
    "doc4 = [w for w in doc4 if not w in sw]\n",
    "p_stems = [porter.stem(word) for word in doc4]\n",
    "p_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from process_words import clean_one_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warm',\n",
       " 'water',\n",
       " 'saffron',\n",
       " 'threads',\n",
       " 'crushed',\n",
       " 'powder',\n",
       " 'pestle',\n",
       " 'mortar',\n",
       " 'unsalted',\n",
       " 'butter',\n",
       " 'olive',\n",
       " 'oil',\n",
       " 'leeks',\n",
       " 'whites',\n",
       " 'tender',\n",
       " 'green',\n",
       " 'parts',\n",
       " 'halved',\n",
       " 'halfmoon',\n",
       " 'shapes',\n",
       " 'washed',\n",
       " 'well',\n",
       " 'shrimp',\n",
       " 'shell',\n",
       " 'deveined',\n",
       " 'washed',\n",
       " 'sea',\n",
       " 'salt',\n",
       " 'herbs',\n",
       " 'choice',\n",
       " 'use',\n",
       " 'cilantro',\n",
       " 'leaves',\n",
       " 'stems',\n",
       " 'italian',\n",
       " 'flatleaf',\n",
       " 'parsley',\n",
       " 'leaves',\n",
       " 'mint',\n",
       " 'leaves']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_one_doc(docs[798])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
