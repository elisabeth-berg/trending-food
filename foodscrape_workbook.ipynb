{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import psycopg2\n",
    "import scraper\n",
    "import process_words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>post_date</th>\n",
       "      <th>title</th>\n",
       "      <th>foods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>Long Life Noodles with Shrimp and Greens</td>\n",
       "      <td>teaspoon sesame oil, for drizzling stalk green...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>Ginger-Onion Whole Steamed Fish</td>\n",
       "      <td>stalks green onions, cut into 3-inch segments,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>Smacked Cucumber</td>\n",
       "      <td>teaspoon sugar cloves garlic, crushed tablespo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>Neck Bones and Lima Beans</td>\n",
       "      <td>salt and pepper, to taste tablespoons canola o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>Angel Wings (Faworki)</td>\n",
       "      <td>pinch sea salt confectioner’s sugar for servin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  post_date                                     title  \\\n",
       "0  27 2018-02-09  Long Life Noodles with Shrimp and Greens   \n",
       "1  28 2018-02-09           Ginger-Onion Whole Steamed Fish   \n",
       "2  29 2018-02-09                          Smacked Cucumber   \n",
       "3  30 2018-02-08                 Neck Bones and Lima Beans   \n",
       "4  31 2018-02-07                     Angel Wings (Faworki)   \n",
       "\n",
       "                                               foods  \n",
       "0  teaspoon sesame oil, for drizzling stalk green...  \n",
       "1  stalks green onions, cut into 3-inch segments,...  \n",
       "2  teaspoon sugar cloves garlic, crushed tablespo...  \n",
       "3  salt and pepper, to taste tablespoons canola o...  \n",
       "4  pinch sea salt confectioner’s sugar for servin...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "food_stems = [process_words.clean_one_doc(doc) for doc in df.foods]\n",
    "title_stems = [process_words.clean_one_doc(doc) for doc in df.title]\n",
    "df['food_stems'] = food_stems\n",
    "df['title_stems'] = title_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>post_date</th>\n",
       "      <th>title</th>\n",
       "      <th>foods</th>\n",
       "      <th>food_stems</th>\n",
       "      <th>title_stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>Long Life Noodles with Shrimp and Greens</td>\n",
       "      <td>teaspoon sesame oil, for drizzling stalk green...</td>\n",
       "      <td>[sesame, oil, drizzling, stalk, green, onion, ...</td>\n",
       "      <td>[long, life, noodles, shrimp, greens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>Ginger-Onion Whole Steamed Fish</td>\n",
       "      <td>stalks green onions, cut into 3-inch segments,...</td>\n",
       "      <td>[stalks, green, onions, segments, kosher, salt...</td>\n",
       "      <td>[ginger, onion, whole, steamed, fish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>Smacked Cucumber</td>\n",
       "      <td>teaspoon sugar cloves garlic, crushed tablespo...</td>\n",
       "      <td>[sugar, cloves, garlic, crushed, soy, sauce, r...</td>\n",
       "      <td>[smacked, cucumber]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>Neck Bones and Lima Beans</td>\n",
       "      <td>salt and pepper, to taste tablespoons canola o...</td>\n",
       "      <td>[salt, pepper, canola, oil, ground, sage, froz...</td>\n",
       "      <td>[neck, bones, lima, beans]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>Angel Wings (Faworki)</td>\n",
       "      <td>pinch sea salt confectioner’s sugar for servin...</td>\n",
       "      <td>[sea, salt, confectioners, sugar, sour, cream,...</td>\n",
       "      <td>[angel, wings, faworki]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  post_date                                     title  \\\n",
       "0  27 2018-02-09  Long Life Noodles with Shrimp and Greens   \n",
       "1  28 2018-02-09           Ginger-Onion Whole Steamed Fish   \n",
       "2  29 2018-02-09                          Smacked Cucumber   \n",
       "3  30 2018-02-08                 Neck Bones and Lima Beans   \n",
       "4  31 2018-02-07                     Angel Wings (Faworki)   \n",
       "\n",
       "                                               foods  \\\n",
       "0  teaspoon sesame oil, for drizzling stalk green...   \n",
       "1  stalks green onions, cut into 3-inch segments,...   \n",
       "2  teaspoon sugar cloves garlic, crushed tablespo...   \n",
       "3  salt and pepper, to taste tablespoons canola o...   \n",
       "4  pinch sea salt confectioner’s sugar for servin...   \n",
       "\n",
       "                                          food_stems  \\\n",
       "0  [sesame, oil, drizzling, stalk, green, onion, ...   \n",
       "1  [stalks, green, onions, segments, kosher, salt...   \n",
       "2  [sugar, cloves, garlic, crushed, soy, sauce, r...   \n",
       "3  [salt, pepper, canola, oil, ground, sage, froz...   \n",
       "4  [sea, salt, confectioners, sugar, sour, cream,...   \n",
       "\n",
       "                             title_stems  \n",
       "0  [long, life, noodles, shrimp, greens]  \n",
       "1  [ginger, onion, whole, steamed, fish]  \n",
       "2                    [smacked, cucumber]  \n",
       "3             [neck, bones, lima, beans]  \n",
       "4                [angel, wings, faworki]  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_vocab = list(set([word for doc in food_stems for word in doc]))\n",
    "title_vocab = list(set([word for doc in title_stems for word in doc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_vocab_dict = {word: i for i, word in enumerate(food_vocab)}\n",
    "title_vocab_dict = {word: i for i, word in enumerate(title_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "food_counts = np.zeros((len(food_stems), len(food_vocab)))\n",
    "for doc_id, words in enumerate(food_stems):\n",
    "    for word in words:\n",
    "        word_id = food_vocab_dict[word]\n",
    "        food_counts[doc_id][word_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', tokenizer=process_words.clean_one_doc)\n",
    "vectors = vectorizer.fit_transform(df.foods).toarray()\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the highest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"cat\", \"pig\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[-1:-n-1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 by average tf-idf\n",
      "['montasio', 'papad', 'grapefuit', 'coconuts', 'kahla', 'chicharrones', 'passionfruit', 'jamn', 'kapika', 'caramels']\n"
     ]
    }
   ],
   "source": [
    "avg = np.sum(vectors, axis=0) / np.sum(vectors > 0, axis=0)\n",
    "print (\"top 10 by average tf-idf\")\n",
    "print (get_top_values(avg, 10, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 by total tf-idf\n",
      "['sugar', 'salt', 'oil', 'fresh', 'butter', 'pepper', 'flour', 'ground', 'olive', 'lemon']\n"
     ]
    }
   ],
   "source": [
    "total = np.sum(vectors, axis=0)\n",
    "print (\"top 10 by total tf-idf\")\n",
    "print (get_top_values(total, 10, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4858, 5383)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5383"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5383"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors[:1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.91981864,  0.91795628,  0.88133154,  0.77065948,\n",
       "        0.73876459,  0.72868118,  0.72657354,  0.69608586,  0.68041406])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.argsort(avg)[-1:-10-1:-1]\n",
    "avg[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['montasio',\n",
       " 'papad',\n",
       " 'grapefuit',\n",
       " 'coconuts',\n",
       " 'kahla',\n",
       " 'chicharrones',\n",
       " 'passionfruit',\n",
       " 'jamn',\n",
       " 'kapika',\n",
       " 'caramels']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[words[i] for i in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
